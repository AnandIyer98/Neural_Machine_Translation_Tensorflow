{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will try to implement a Neural Machine Tranlation system with tensorflow.\n",
    "We will be using the code from the files in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import NMT_Model\n",
    "import nmt_data_utils\n",
    "import nmt_model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "The dataset we will be working with are english and german sentences from the European Parliament. It contains about 2 million sentence pairs, but we will only use a small fraction of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the english texts\n",
    "with open('/Users/thomas/Jupyter_Notebooks/Play/Neural_Machine_Translation/de-en/europarl-v7.de-en.en',\n",
    "          'r',\n",
    "          encoding = 'utf-8') as f:\n",
    "    en = f.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the german texts\n",
    "with open('/Users/thomas/Jupyter_Notebooks/Play/Neural_Machine_Translation/de-en/europarl-v7.de-en.de',\n",
    "          'r',\n",
    "          encoding = 'utf-8') as f:\n",
    "    de = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920209, 1920209)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en), len(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Resumption of the session\\n', 'Wiederaufnahme der Sitzungsperiode\\n') \n",
      "\n",
      "('I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\\n', 'Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\\n') \n",
      "\n",
      "(\"Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\\n\", 'Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\\n') \n",
      "\n",
      "('You have requested a debate on this subject in the course of the next few days, during this part-session.\\n', 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.\\n') \n",
      "\n",
      "(\"In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\\n\", 'Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen -, allen Opfern der Stürme, insbesondere in den verschiedenen Ländern der Europäischen Union, in einer Schweigeminute zu gedenken.\\n') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first 5 sentence pairs. \n",
    "for line in zip(en[:5], de[:5]):\n",
    "    print(line, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary new lines. \n",
    "de = [line.strip() for line in de]\n",
    "en = [line.strip() for line in en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(47, 7266),\n",
       " (49, 7113),\n",
       " (45, 6928),\n",
       " (35, 6833),\n",
       " (48, 6813),\n",
       " (21, 6642),\n",
       " (44, 6519),\n",
       " (46, 6491),\n",
       " (43, 6443),\n",
       " (40, 6130),\n",
       " (42, 6108),\n",
       " (37, 5824),\n",
       " (41, 5793),\n",
       " (34, 5711),\n",
       " (39, 5682),\n",
       " (29, 5659),\n",
       " (38, 5599),\n",
       " (33, 5496),\n",
       " (36, 5452),\n",
       " (31, 4651),\n",
       " (32, 4554),\n",
       " (30, 4441),\n",
       " (27, 4117),\n",
       " (28, 4062),\n",
       " (26, 3989),\n",
       " (25, 3911),\n",
       " (24, 3762),\n",
       " (23, 3473),\n",
       " (22, 2776)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will only use sentences of similar lengths in order to make training easier. \n",
    "len_en = [len(sent) for sent in en if 20 < len(sent) < 50]\n",
    "len_dist = Counter(len_en).most_common()\n",
    "len_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158238"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 158238 sentences that contain betwenn 20 and 50 words.\n",
    "len(len_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_de = []\n",
    "_en = []\n",
    "for sent_de, sent_en in zip(de, en):\n",
    "    if 20 < len(sent_en) < 50:\n",
    "        _de.append(sent_de)\n",
    "        _en.append(sent_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.29 s, sys: 35 ms, total: 1.32 s\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# but we will not use all 150 000 sentences, only 5000 for the beginning. \n",
    "en_preprocessed, en_most_common = nmt_data_utils.preprocess(_en[:5000])\n",
    "de_preprocessed, de_most_common = nmt_data_utils.preprocess(_de[:5000], language = 'german')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_preprocessed), len(de_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some of the sentences there is not german or english counterpart, i.e. only an empy array []\n",
    "# therefore we will remove those sentence pairs.\n",
    "en_preprocessed_clean, de_preprocessed_clean = [], []\n",
    "\n",
    "for sent_en, sent_de in zip(en_preprocessed, de_preprocessed):\n",
    "    if sent_en != [] and sent_de != []:\n",
    "        en_preprocessed_clean.append(sent_en)\n",
    "        de_preprocessed_clean.append(sent_de)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4988, 4988)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_preprocessed_clean), len(de_preprocessed_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:\n",
      " ['resumption', 'of', 'the', 'session']\n",
      "German:\n",
      " ['wiederaufnahme', 'der', 'sitzungsperiode'] \n",
      "\n",
      "\n",
      "\n",
      "English:\n",
      " ['please', 'rise', ',', 'then', ',', 'for', 'this', 'minute', \"'\", 's', 'silence', '.']\n",
      "German:\n",
      " ['ich', 'bitte', 'sie', ',', 'sich', 'zu', 'einer', 'schweigeminute', 'zu', 'erheben', '.'] \n",
      "\n",
      "\n",
      "\n",
      "English:\n",
      " ['(', 'the', 'house', 'rose', 'and', 'observed', 'a', 'minute', \"'\", 's', 'silence', ')']\n",
      "German:\n",
      " ['(', 'das', 'parlament', 'erhebt', 'sich', 'zu', 'einer', 'schweigeminute', '.', ')'] \n",
      "\n",
      "\n",
      "\n",
      "English:\n",
      " ['madam', 'president', ',', 'on', 'a', 'point', 'of', 'order', '.']\n",
      "German:\n",
      " ['frau', 'präsidentin', ',', 'zur', 'geschäftsordnung', '.'] \n",
      "\n",
      "\n",
      "\n",
      "English:\n",
      " ['madam', 'president', ',', 'on', 'a', 'point', 'of', 'order', '.']\n",
      "German:\n",
      " ['frau', 'präsidentin', ',', 'zur', 'geschäftsordnung', '.'] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for e, d in zip(en_preprocessed_clean, de_preprocessed_clean[:5]):\n",
    "    print('English:\\n', e)\n",
    "    print('German:\\n', d, '\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('.', 3981),\n",
       "  ('the', 1864),\n",
       "  ('is', 1371),\n",
       "  ('this', 860),\n",
       "  (',', 842),\n",
       "  ('to', 822),\n",
       "  ('we', 736),\n",
       "  ('i', 677),\n",
       "  ('that', 619),\n",
       "  ('a', 611),\n",
       "  ('of', 592),\n",
       "  ('it', 486),\n",
       "  ('not', 474),\n",
       "  (')', 451),\n",
       "  ('(', 450)],\n",
       " 4135,\n",
       " 5410)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_most_common[:15], len(en_most_common), len(de_most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can create oyr lookup dicts for english and german, i.e. our vocab. \n",
    "# we will also include special tokens, later on used in the model. \n",
    "specials = [\"<unk>\", \"<s>\", \"</s>\", '<pad>']\n",
    "\n",
    "en_word2ind, en_ind2word, en_vocab_size = nmt_data_utils.create_vocab(en_most_common, specials)\n",
    "de_word2ind, de_ind2word, de_vocab_size = nmt_data_utils.create_vocab(de_most_common, specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4139, 5414)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab_size, de_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to feed the sentences to the network, we have to convert them to ints, corresponding to their indices\n",
    "# in the lookup dicts. \n",
    "# we reverse the source language sentences, i.e. the english sentences as this alleviates learning for the seq2seq \n",
    "# model. Apart from this we also include EndOfSentence and StartOfSentence tags, which are needed as well. \n",
    "en_inds, en_unknowns = nmt_data_utils.convert_to_inds(en_preprocessed_clean, en_word2ind, reverse = True, eos = True)\n",
    "de_inds, de_unknowns = nmt_data_utils.convert_to_inds(de_preprocessed_clean, de_word2ind, sos = True, eos = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['session', 'the', 'of', 'resumption', '</s>'],\n",
       " ['.',\n",
       "  'silence',\n",
       "  's',\n",
       "  \"'\",\n",
       "  'minute',\n",
       "  'this',\n",
       "  'for',\n",
       "  ',',\n",
       "  'then',\n",
       "  ',',\n",
       "  'rise',\n",
       "  'please',\n",
       "  '</s>']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nmt_data_utils.convert_to_words(sentence, en_ind2word) for sentence in  en_inds[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'wiederaufnahme', 'der', 'sitzungsperiode', '</s>'],\n",
       " ['<s>',\n",
       "  'ich',\n",
       "  'bitte',\n",
       "  'sie',\n",
       "  ',',\n",
       "  'sich',\n",
       "  'zu',\n",
       "  'einer',\n",
       "  'schweigeminute',\n",
       "  'zu',\n",
       "  'erheben',\n",
       "  '.',\n",
       "  '</s>']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nmt_data_utils.convert_to_words(sentence, de_ind2word) for sentence in  de_inds[:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Now we are ready to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams. \n",
    "# those are probably not perfect, but work fine for now. \n",
    "num_layers_encoder = 4\n",
    "num_layers_decoder = 4\n",
    "rnn_size_encoder = 128\n",
    "rnn_size_decoder = 128\n",
    "embedding_dim = 300\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "clip = 5\n",
    "keep_probability = 0.8\n",
    "learning_rate = 0.01\n",
    "learning_rate_decay_steps = 1000\n",
    "learning_rate_decay = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the graph and train the model. \n",
    "nmt_model_utils.reset_graph()\n",
    "\n",
    "nmt = NMT_Model.NMT(en_word2ind,\n",
    "                    en_ind2word,\n",
    "                    de_word2ind,\n",
    "                    de_ind2word,\n",
    "                    './models/local_one/my_model',\n",
    "                    'TRAIN',\n",
    "                    embedding_dim = embedding_dim,\n",
    "                    num_layers_encoder = num_layers_encoder,\n",
    "                    num_layers_decoder = num_layers_decoder,\n",
    "                    batch_size = batch_size,\n",
    "                    clip = clip,\n",
    "                    keep_probability = keep_probability,\n",
    "                    learning_rate = learning_rate,\n",
    "                    epochs = epochs,\n",
    "                    rnn_size_encoder = rnn_size_encoder,\n",
    "                    rnn_size_decoder = rnn_size_decoder, \n",
    "                    learning_rate_decay_steps = learning_rate_decay_steps,\n",
    "                    learning_rate_decay = learning_rate_decay)\n",
    "  \n",
    "nmt.build_graph()\n",
    "nmt.train(en_inds, de_inds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "We can now use the trained model to translate english sentences to german. For now we will only translate senteces the model originally was trained on. \n",
    "\n",
    "**Note:** the network was only trained on 5000 sentences for 50 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_de_inds, _de_unknowns = nmt_data_utils.convert_to_inds(de_preprocessed_clean, de_word2ind, sos = True,  eos = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/thomas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Graph built.\n",
      "Restore graph from  ./models/local_one/my_model\n",
      "INFO:tensorflow:Restoring parameters from ./models/local_one/my_model\n"
     ]
    }
   ],
   "source": [
    "# the inference model does not necessaryly need to get input batches. we can just give it. the whole input\n",
    "# data, but the the batchsize has to be specified as the lenght of the input data.\n",
    "nmt_model_utils.reset_graph()\n",
    "\n",
    "nmt = NMT_Model.NMT(en_word2ind,\n",
    "                    en_ind2word,\n",
    "                    de_word2ind,\n",
    "                    de_ind2word,\n",
    "                    './models/local_one/my_model',\n",
    "                    'INFER',\n",
    "                    num_layers_encoder = num_layers_encoder,\n",
    "                    num_layers_decoder = num_layers_decoder,\n",
    "                    batch_size = len(en_inds[:50]),\n",
    "                    keep_probability = 1.0,\n",
    "                    learning_rate = 0.0,\n",
    "                    beam_width = 0,\n",
    "                    rnn_size_encoder = rnn_size_encoder,\n",
    "                    rnn_size_decoder = rnn_size_decoder)\n",
    "\n",
    "nmt.build_graph()\n",
    "preds = nmt.infer(en_inds[:50], restore_path =  './models/local_one/my_model', targets = _de_inds[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "resumption of the session\n",
      "\n",
      "Actual translation:\n",
      "wiederaufnahme der sitzungsperiode\n",
      "\n",
      "Created translation:\n",
      "wiederaufnahme der sitzungsperiode\n",
      "\n",
      "Bleu-score: 1.0\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "please rise , then , for this minute ' s silence .\n",
      "\n",
      "Actual translation:\n",
      "ich bitte sie , sich zu einer schweigeminute zu erheben .\n",
      "\n",
      "Created translation:\n",
      "ich bitte ich forderung forderung vor vor schweigeminute erheben erheben\n",
      "\n",
      "Bleu-score: 0.41545589177443254\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "( the house rose and observed a minute ' s silence )\n",
      "\n",
      "Actual translation:\n",
      "( das parlament erhebt sich zu einer schweigeminute . )\n",
      "\n",
      "Created translation:\n",
      "( das parlament erhebt der einer einer schweigeminute . )\n",
      "\n",
      "Bleu-score: 0.5253819788848316\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "madam president , on a point of order .\n",
      "\n",
      "Actual translation:\n",
      "frau präsidentin , zur geschäftsordnung .\n",
      "\n",
      "Created translation:\n",
      "frau präsidentin , zur geschäftsordnung .\n",
      "\n",
      "Bleu-score: 1.0\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "madam president , on a point of order .\n",
      "\n",
      "Actual translation:\n",
      "frau präsidentin , zur geschäftsordnung .\n",
      "\n",
      "Created translation:\n",
      "frau präsidentin , zur geschäftsordnung .\n",
      "\n",
      "Bleu-score: 1.0\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "thank you , mr segni , i shall do so gladly .\n",
      "\n",
      "Actual translation:\n",
      "vielen dank , herr segni , das will ich gerne tun .\n",
      "\n",
      "Created translation:\n",
      "vielen dank , ich segni , , , , , ! .\n",
      "\n",
      "Bleu-score: 0.3551496090063711\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "it is the case of alexander nikitin .\n",
      "\n",
      "Actual translation:\n",
      "das ist der fall von alexander nikitin .\n",
      "\n",
      "Created translation:\n",
      "das ist der fall alexander alexander nikitin .\n",
      "\n",
      "Bleu-score: 0.5\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "it will , i hope , be examined in a positive light .\n",
      "\n",
      "Actual translation:\n",
      "ich hoffe , daß dort in ihrem sinne entschieden wird .\n",
      "\n",
      "Created translation:\n",
      "ich bitte , , , , ihrem ihrem von von .\n",
      "\n",
      "Bleu-score: 0.7765453555044466\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "why are there no fire instructions ?\n",
      "\n",
      "Actual translation:\n",
      "warum finden keine brandschutzbelehrungen statt ?\n",
      "\n",
      "Created translation:\n",
      "warum gibt statt brandschutzbelehrungen statt statt\n",
      "\n",
      "Bleu-score: 0.5623413251903491\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "why are no-smoking areas not enforced ?\n",
      "\n",
      "Actual translation:\n",
      "warum wird in den nichtraucherzonen das rauchverbot nicht durchgesetzt ?\n",
      "\n",
      "Created translation:\n",
      "warum wird den den nichtraucherzonen rauchverbot rauchverbot\n",
      "\n",
      "Bleu-score: 0.4550524645870584\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "mr berenguer fuster , we shall check all this .\n",
      "\n",
      "Actual translation:\n",
      "lieber kollege , wir werden das prüfen .\n",
      "\n",
      "Created translation:\n",
      "lieber kollege , wir wir das prüfen .\n",
      "\n",
      "Bleu-score: 0.5\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "we do not know what is happening .\n",
      "\n",
      "Actual translation:\n",
      "wir wissen nicht , was passiert .\n",
      "\n",
      "Created translation:\n",
      "wir brauchen wir wir wir passiert .\n",
      "\n",
      "Bleu-score: 0.5169731539571706\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "relating to wednesday :\n",
      "\n",
      "Actual translation:\n",
      "zum mittwoch :\n",
      "\n",
      "Created translation:\n",
      "zum mittwoch : :\n",
      "\n",
      "Bleu-score: 0.7071067811865476\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "( applause from the pse group )\n",
      "\n",
      "Actual translation:\n",
      "( beifall der pse-fraktion )\n",
      "\n",
      "Created translation:\n",
      "( beifall der pse-fraktion )\n",
      "\n",
      "Bleu-score: 1.0\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "mr hänsch represented you on this occasion .\n",
      "\n",
      "Actual translation:\n",
      "der kollege hänsch hat sie dort vertreten .\n",
      "\n",
      "Created translation:\n",
      "dort kollege , , , ausgenommen vertreten .\n",
      "\n",
      "Bleu-score: 0.5169731539571706\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "we then put it to a vote .\n",
      "\n",
      "Actual translation:\n",
      "wir haben dann abgestimmt .\n",
      "\n",
      "Created translation:\n",
      "wir haben wir abgestimmt . .\n",
      "\n",
      "Bleu-score: 0.7186082239261684\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "there was a vote on this matter .\n",
      "\n",
      "Actual translation:\n",
      "es gab eine abstimmung zu diesem punkt .\n",
      "\n",
      "Created translation:\n",
      "es gibt es , mißverständnis zeit zeit . .\n",
      "\n",
      "Bleu-score: 0.6865890479690392\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "all of the others were of a different opinion .\n",
      "\n",
      "Actual translation:\n",
      "alle anderen waren anderer meinung .\n",
      "\n",
      "Created translation:\n",
      "alle anderen anderer anderer richtlinie\n",
      "\n",
      "Bleu-score: 0.5095231471606585\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "that was the decision .\n",
      "\n",
      "Actual translation:\n",
      "das war der beschluß .\n",
      "\n",
      "Created translation:\n",
      "das war das entscheidung .\n",
      "\n",
      "Bleu-score: 0.6223329772884784\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "i should now like to comment on the issue itself .\n",
      "\n",
      "Actual translation:\n",
      "jetzt möchte ich zur sache selbst etwas sagen .\n",
      "\n",
      "Created translation:\n",
      "ich haben mich nicht auf debatte debatte vor .\n",
      "\n",
      "Bleu-score: 0.6865890479690392\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "there is no such document !\n",
      "\n",
      "Actual translation:\n",
      "ein solches dokument gibt es nicht !\n",
      "\n",
      "Created translation:\n",
      "es gibt dokument dokument sich : !\n",
      "\n",
      "Bleu-score: 0.8694417438899827\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "we have agreed to this .\n",
      "\n",
      "Actual translation:\n",
      "wir haben dem zugestimmt .\n",
      "\n",
      "Created translation:\n",
      "wir haben wir zugestimmt zugestimmt . .\n",
      "\n",
      "Bleu-score: 0.6606328636027614\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "( applause from the ppe-de group )\n",
      "\n",
      "Actual translation:\n",
      "( beifall von der ppe-de-fraktion )\n",
      "\n",
      "Created translation:\n",
      "( beifall von ppe-de-fraktion ppe-de-fraktion )\n",
      "\n",
      "Bleu-score: 0.5946035575013605\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "( parliament rejected the request ) president .\n",
      "\n",
      "Actual translation:\n",
      "( das parlament lehnt den antrag ab . ) die präsidentin .\n",
      "\n",
      "Created translation:\n",
      "( das parlament lehnt den antrag .\n",
      "\n",
      "Bleu-score: 0.4116538266387963\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "thank you , mr poettering .\n",
      "\n",
      "Actual translation:\n",
      "vielen dank , herr poettering .\n",
      "\n",
      "Created translation:\n",
      "vielen dank , poettering poettering\n",
      "\n",
      "Bleu-score: 0.49473859088183875\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "it is not a lot to ask .\n",
      "\n",
      "Actual translation:\n",
      "das ist nicht zuviel verlangt .\n",
      "\n",
      "Created translation:\n",
      "das ist nicht ist . .\n",
      "\n",
      "Bleu-score: 0.5081327481546147\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "madam president , has my vote been counted ?\n",
      "\n",
      "Actual translation:\n",
      "frau präsidentin ! ist meine stimme mitgezählt worden ?\n",
      "\n",
      "Created translation:\n",
      "frau präsidentin , ich mitgezählt mitgezählt mitgezählt mitgezählt\n",
      "\n",
      "Bleu-score: 0.42456725576936255\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "my vote was `` in favour '' .\n",
      "\n",
      "Actual translation:\n",
      "ich habe `` dafür `` gestimmt .\n",
      "\n",
      "Created translation:\n",
      "die handelt sich um `` `` .\n",
      "\n",
      "Bleu-score: 0.8091067115702212\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "there is no room for amendments .\n",
      "\n",
      "Actual translation:\n",
      "änderungen sind nicht möglich .\n",
      "\n",
      "Created translation:\n",
      "zunächst gibt ein änderungsanträge .\n",
      "\n",
      "Bleu-score: 0.668740304976422\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "this is an important matter .\n",
      "\n",
      "Actual translation:\n",
      "das ist eine wichtige angelegenheit .\n",
      "\n",
      "Created translation:\n",
      "das ist ein eine eine .\n",
      "\n",
      "Bleu-score: 0.6042750794713536\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "you did not call me either .\n",
      "\n",
      "Actual translation:\n",
      "sie haben mich auch nicht aufgerufen .\n",
      "\n",
      "Created translation:\n",
      "sie sie sie , aufgerufen aufgerufen .\n",
      "\n",
      "Bleu-score: 0.5169731539571706\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "i am terribly sorry , mr hänsch and mr cox .\n",
      "\n",
      "Actual translation:\n",
      "das tut mir leid , herr hänsch und herr cox .\n",
      "\n",
      "Created translation:\n",
      "ich verstehe mir leid , herr hänsch herr cox cox .\n",
      "\n",
      "Bleu-score: 0.4366835442847812\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "i did not see you asking to speak .\n",
      "\n",
      "Actual translation:\n",
      "ich hatte nicht gesehen , daß sie ums wort gebeten hatten .\n",
      "\n",
      "Created translation:\n",
      "ich bitte sie , , , , ums . .\n",
      "\n",
      "Bleu-score: 0.688467755321249\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "this seems to me to be a workable solution .\n",
      "\n",
      "Actual translation:\n",
      "ich halte dieses vorgehen für angemessen .\n",
      "\n",
      "Created translation:\n",
      "ich halte das das nicht . .\n",
      "\n",
      "Bleu-score: 0.5169731539571706\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "( the order of business was adopted thus amended )\n",
      "\n",
      "Actual translation:\n",
      "( das parlament genehmigt den geänderten arbeitsplan . )\n",
      "\n",
      "Created translation:\n",
      "( das parlament nimmt den geänderten arbeitsplan . .\n",
      "\n",
      "Bleu-score: 0.43167001068522526\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "i would urge you to endorse this .\n",
      "\n",
      "Actual translation:\n",
      "ich bitte sie um zustimmung .\n",
      "\n",
      "Created translation:\n",
      "ich bitte sie bitte zustimmung .\n",
      "\n",
      "Bleu-score: 0.5946035575013605\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "i congratulate him on his excellent report .\n",
      "\n",
      "Actual translation:\n",
      "ich beglückwünsche ihn zu seinem ausgezeichneten bericht .\n",
      "\n",
      "Created translation:\n",
      "ich beglückwünsche ihn zwei ausgezeichneten ausgezeichneten ausgezeichneten .\n",
      "\n",
      "Bleu-score: 0.41535092372063953\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "this is a pity , in a sense .\n",
      "\n",
      "Actual translation:\n",
      "in gewissem sinne bedauere ich das .\n",
      "\n",
      "Created translation:\n",
      "ich gewissem ich bedauere bedauere . .\n",
      "\n",
      "Bleu-score: 0.8694417438899827\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "in short , the issue is an important one .\n",
      "\n",
      "Actual translation:\n",
      "kurzum , ein ernstes problem .\n",
      "\n",
      "Created translation:\n",
      "kurzum waren ein ernstes ernstes . . .\n",
      "\n",
      "Bleu-score: 0.5169731539571706\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "i would like to mention one final point .\n",
      "\n",
      "Actual translation:\n",
      "gestatten sie mir noch einen letzten hinweis .\n",
      "\n",
      "Created translation:\n",
      "ich möchte eine einen einen letzten nennen .\n",
      "\n",
      "Bleu-score: 0.48109772909788073\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "this , however , does not seem feasible .\n",
      "\n",
      "Actual translation:\n",
      "allerdings scheint das nicht machbar zu sein .\n",
      "\n",
      "Created translation:\n",
      "es scheint , nicht nicht nicht . .\n",
      "\n",
      "Bleu-score: 0.7825422900366437\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "i should like to make just a few comments .\n",
      "\n",
      "Actual translation:\n",
      "ich möchte nur wenige anmerkungen machen .\n",
      "\n",
      "Created translation:\n",
      "ich möchte einige einige anmerkungen . .\n",
      "\n",
      "Bleu-score: 0.5555238068023582\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "my third point has also been mentioned already .\n",
      "\n",
      "Actual translation:\n",
      "der dritte punkt wurde auch schon erwähnt .\n",
      "\n",
      "Created translation:\n",
      "der dritte dritte die die ein erwähnt .\n",
      "\n",
      "Bleu-score: 0.6147881529512643\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "the debate is closed .\n",
      "\n",
      "Actual translation:\n",
      "die aussprache ist geschlossen .\n",
      "\n",
      "Created translation:\n",
      "die aussprache ist geschlossen .\n",
      "\n",
      "Bleu-score: 1.0\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "the vote will take place tomorrow at 12 p.m .\n",
      "\n",
      "Actual translation:\n",
      "die abstimmung findet morgen um 12.00 uhr statt .\n",
      "\n",
      "Created translation:\n",
      "die abstimmung findet morgen um 12.00 uhr statt .\n",
      "\n",
      "Bleu-score: 1.0\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "transport of dangerous goods by road\n",
      "\n",
      "Actual translation:\n",
      "gefahrguttransport auf der straße\n",
      "\n",
      "Created translation:\n",
      "gefahrguttransport in der straße\n",
      "\n",
      "Bleu-score: 0.7071067811865475\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "i thought that it was quite superb .\n",
      "\n",
      "Actual translation:\n",
      "ich fand das ganz hervorragend .\n",
      "\n",
      "Created translation:\n",
      "ich fand ein hervorragend hervorragend .\n",
      "\n",
      "Bleu-score: 0.7186082239261684\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "this directive is a contribution to this .\n",
      "\n",
      "Actual translation:\n",
      "diese richtlinie ist ein beitrag dazu .\n",
      "\n",
      "Created translation:\n",
      "das ist ein ein . .\n",
      "\n",
      "Bleu-score: 0.4760116549244004\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "the debate is closed .\n",
      "\n",
      "Actual translation:\n",
      "die aussprache ist geschlossen .\n",
      "\n",
      "Created translation:\n",
      "die aussprache ist geschlossen .\n",
      "\n",
      "Bleu-score: 1.0\n",
      "\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "the vote will take place tomorrow at 12 p.m .\n",
      "\n",
      "Actual translation:\n",
      "die abstimmung findet morgen um 12.00 uhr statt .\n",
      "\n",
      "Created translation:\n",
      "die abstimmung findet morgen um 12.00 uhr statt .\n",
      "\n",
      "Bleu-score: 1.0\n",
      "\n",
      "\n",
      "\n",
      "Total Bleu Score: 0.6484666095403697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/Users/thomas/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/Users/thomas/anaconda3/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# show some of the created translations\n",
    "# Note: the way bleu score is probably not the perfect way to do it\n",
    "nmt_model_utils.sample_results(preds, en_ind2word, de_ind2word, en_word2ind, de_word2ind, _de_inds[:50], en_inds[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model is hard on my laptop, so I only trained it on 5000 sentences. It would be interesting to scale up the model, to see how it really performs. In the state it is now it obviously does not generalize well and create good, meaningful translations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
